{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02cc6ac5-209d-460b-8a73-ef063a24aa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw features data:    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
      "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
      "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
      "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
      "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
      "\n",
      "    ca  thal  \n",
      "0  0.0   6.0  \n",
      "1  3.0   3.0  \n",
      "2  2.0   7.0  \n",
      "3  0.0   3.0  \n",
      "4  0.0   3.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Fetch dataset\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "print(\"Raw features data:\", heart_disease.data.features[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "244ecda9-f8a3-4459-9ca1-1f482c78128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  cp  chol  fbs  restecg  thalach  exang  oldpeak  slope   ca  thal\n",
       "0      1   1   233    1        2      150      0      2.3      3  0.0   6.0\n",
       "1      1   4   286    0        2      108      1      1.5      2  3.0   3.0\n",
       "2      1   4   229    0        2      129      1      2.6      2  2.0   7.0\n",
       "3      1   3   250    0        0      187      0      3.5      3  0.0   3.0\n",
       "4      0   2   204    0        2      172      0      1.4      1  0.0   3.0\n",
       "..   ...  ..   ...  ...      ...      ...    ...      ...    ...  ...   ...\n",
       "298    1   1   264    0        0      132      0      1.2      2  0.0   7.0\n",
       "299    1   4   193    1        0      141      0      3.4      2  2.0   7.0\n",
       "300    1   4   131    0        0      115      1      1.2      2  1.0   7.0\n",
       "301    0   2   236    0        2      174      0      0.0      2  1.0   3.0\n",
       "302    1   3   175    0        0      173      0      0.0      1  NaN   3.0\n",
       "\n",
       "[303 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1(5 pts) Clean your dataset to turn categorical values into numerical ones. One-hot encoding is likely the answer, but it depends on the dataset. Your data may have ordinal columns, for example where one-hot encoding is not as appropriate.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "X = pd.DataFrame(heart_disease.data.features, columns=heart_disease.data.feature_names)\n",
    "y = pd.Series(heart_disease.data.targets.squeeze(), name='Outcome')\n",
    "class_labels = LabelEncoder()\n",
    "columns = ['sex','cp','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']\n",
    "#USED MEDIUM.COM\n",
    "heartdisease_hot = pd.get_dummies(X[columns])\n",
    "heartdisease_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e4d4a01-fa03-4c95-9782-f220c2cb69bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02960914256257763\n"
     ]
    }
   ],
   "source": [
    "#2(3 pts) Perform univariate linear regression on the dataset. Select your variable to predict. How well did this model perform? Is this a good approach for this dataset? Why or why not? \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "heartdisease_hot = heartdisease_hot[['sex','cp','chol','fbs','restecg', 'exang','oldpeak','slope','ca']].dropna()\n",
    "#Redefining X and Y\n",
    "X = np.array(heartdisease_hot['sex']).reshape(-1,1)\n",
    "y = np.array(heartdisease_hot['chol']).reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)\n",
    "y_pred = regression_model.predict(X_test)\n",
    "y_pred\n",
    "accuracy_score = regression_model.score(X_test, y_test)\n",
    "print(accuracy_score)\n",
    "#The model did not perform well, and now this was not a good approach because the values aren't just 1 and 0 and therefore this is a innapropriate model for this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c749426-dd0e-47a2-a22e-bf136308e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1]\n",
      "<class 'numpy.ndarray'>\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "#3(8 pts) Perform KNN on this dataset. As part of this, write a function that selects the optimal value of k. How well did this model perform?\n",
    "#The model performed not too badly because it was 0.73 a lot better than 0.02 and is significant.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "X = heartdisease_hot.drop(['sex'], axis = 1)\n",
    "y = heartdisease_hot['sex']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) \n",
    "X_test = sc.fit_transform(X_test)\n",
    "knn = KNeighborsClassifier(n_neighbors=15) \n",
    "knn.fit(X_train, y_train) \n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)\n",
    "print(type(y_pred))\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1486d1b-f362-4390-879e-3bb0fb1448fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6943310657596372\n"
     ]
    }
   ],
   "source": [
    "#4(6 pts) Work with your dataset to perform logistic regression. How well did this perform?\n",
    "#It has a 69% value so I don't think it means very good nor very bad, so slightly statistically significant.\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "acc_train=[]\n",
    "acc_test=[]\n",
    "\n",
    "neighbors=range(1,50)\n",
    "\n",
    "for neighbor in neighbors:\n",
    "    KNN=KNeighborsClassifier(n_neighbors=neighbor)\n",
    "    KNN.fit(X_train,y_train)\n",
    "    acc_train.append(KNN.score(X_train,y_train))\n",
    "    acc_test.append(KNN.score(X_test,y_test))\n",
    "mean_accuracy = sum(acc_test) / len(acc_test)\n",
    "print(\"Mean accuracy:\", mean_accuracy)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b28b49ea-6979-44c9-8a60-1164cc1d1e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with normalization: 0.6065573770491803\n",
      "Confusion Matrix (normalized):\n",
      " [[31  1  1  0  0]\n",
      " [ 6  4  1  0  0]\n",
      " [ 2  1  0  4  0]\n",
      " [ 0  1  4  2  0]\n",
      " [ 0  2  0  1  0]]\n",
      "Classification Report (normalized):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86        33\n",
      "           1       0.44      0.36      0.40        11\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.29      0.29      0.29         7\n",
      "           4       1.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.61        61\n",
      "   macro avg       0.51      0.32      0.31        61\n",
      "weighted avg       0.59      0.61      0.57        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5. (3 pts) Perform normalization on your dataset. Does it change the performance for 2-4? What is the best measure of performance for your dataset (accuracy or something else) and why?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "X = pd.DataFrame(heart_disease.data.features, columns=heart_disease.data.feature_names)\n",
    "y = heart_disease.data.targets.squeeze()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test):\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, zero_division=1)\n",
    "    print(\"Accuracy with normalization:\", accuracy)\n",
    "    print(\"Confusion Matrix (normalized):\\n\", confusion)\n",
    "    print(\"Classification Report (normalized):\\n\", report)\n",
    "train_and_evaluate_model(X_train_normalized, X_test_normalized, y_train, y_test)\n",
    "\n",
    "\n",
    "#Yes the performance does change with different classes. The f1-score changes with different classifications because the data that comes from classification can vary, \n",
    "#each class doesn't have the same data size.Also there can be false negatives's and positives. It's one of the biggest issues with classification reports,\n",
    "#but that is why we used normalization to eliminate that. The F1 score is the gold standard for performance/accuracy. All code was adapted from Joel grus network analysis and I used codes for geeks for the squeeze. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "(3 pts) What is a neural network? What are the general steps required to build a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network functions like how a brain wound work. There is an input and an output and then a hidden layer that considers the best ouptut based off data and training. \n",
    "To build a neural network in Python, first, clearly define the problem, stating explicitly whether it is a regression or classification model. Then, the dataset must be of high quality, large, and minimally biased. Split the data into training, validation, and test sets. After that, specify the architecture by selecting the number of layers and neurons. Typically, the input layer matches the number of features in your data, hidden layers use some sort of activation function (ReLUs, for example); the output layer is matched to the number of target variables. The activation functions might become something like softmax for classification or linear for regression problems. Train the model: Choose an appropriate loss function-end, such as Mean Squared Error for regression or Cross-Entropy for classification-along with an optimizer such as Adam or Gradient Descent. Use several epochs and batch process with 'performance monitoring' of metrics. Apply dropout, regularization, or data augmentation to improve generalization and avoid overfitting; fine-tune the hyperparameters, such as learning rate or number of neurons. Once the model is trained, evaluate its performance on unseen data using accuracy in the case of a classification task or RMSE for regression. Deploy the trained model to do useful tasks, perhaps in application or API form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "(3 pts) Generally, how do you check the performance of a neural network? Why is this the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why MSE is commonly used for neural networks on regression tasks is that it punishes large errors harder, which is perfect for those applications where one wants to minimize huge deviations. Being differentiable, it ensures smooth optimization during training and provides a clear quantitative measure of performance. It is simple to compute, interpretable, and lower values indicate better predictions. However, it is sensitive to outliers; hence, other alternatives like MAE or Huber loss may be preferred when dealing with noisy datasets. For classification tasks, metrics such as cross-entropy loss will be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 \n",
    "(4 pts) Clean the data or do additional cleaning if you have used the dataset for another assignment. Specify the improvements (at least 2) that you made to your cleaning if you selected the dataset before. If you select one with a low number or records, consider oversampling. \n",
    "\n",
    "I added LDA and dimensionality reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.1099\n",
      "Accuracy: 0.890060\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#reg preprocessing\n",
    "adult = fetch_ucirepo(id=2)\n",
    "data_features = pd.DataFrame(adult.data.features, columns=adult.data.feature_names)\n",
    "data_targets = pd.Series(adult.data.targets.squeeze(), name='income')\n",
    "data = pd.concat([data_features, data_targets], axis=1)\n",
    "data = pd.get_dummies(data)\n",
    "sc = StandardScaler()\n",
    "numeric_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "data[numeric_cols] = sc.fit_transform(data[numeric_cols])\n",
    "X = data.drop(['income_<=50K', 'income_>50K'], axis=1).values\n",
    "y = data['income_>50K'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "#Dimensional reduction\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_lda, y_train)\n",
    "y_predicted = model.predict(X_test_lda)\n",
    "#got a bool error\n",
    "y_test_int = y_test.astype(int)\n",
    "y_predicted_int = y_predicted.astype(int)\n",
    "accuracy = model.score(X_test_lda, y_test)\n",
    "mse = mean_squared_error(y_test_int, y_predicted_int)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n",
    "(10 pts) Create a neural network using Keras or PyTorch to predict the outcome of your datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.0000,  95.0000,  60.0000,  ...,  23.9000,   0.2600,  22.0000],\n",
      "        [  5.0000, 105.0000,  72.0000,  ...,  36.9000,   0.1590,  28.0000],\n",
      "        [  0.0000, 135.0000,  68.0000,  ...,  42.3000,   0.3650,  24.0000],\n",
      "        ...,\n",
      "        [ 10.0000, 101.0000,  86.0000,  ...,  45.6000,   1.1360,  38.0000],\n",
      "        [  0.0000, 141.0000,   0.0000,  ...,  42.4000,   0.2050,  29.0000],\n",
      "        [  0.0000, 125.0000,  96.0000,  ...,  22.5000,   0.2620,  21.0000]])\n",
      "Epoch number: 1 with loss 0.7168329358100891\n",
      "Epoch number: 11 with loss 0.6524671912193298\n",
      "Epoch number: 21 with loss 0.630030632019043\n",
      "Epoch number: 31 with loss 0.6092545986175537\n",
      "Epoch number: 41 with loss 0.5873100757598877\n",
      "Epoch number: 51 with loss 0.5649566650390625\n",
      "Epoch number: 61 with loss 0.5510146021842957\n",
      "Epoch number: 71 with loss 0.535936713218689\n",
      "Epoch number: 81 with loss 0.5241531133651733\n",
      "Epoch number: 91 with loss 0.5143421292304993\n",
      "Epoch number: 101 with loss 0.5075693130493164\n",
      "Epoch number: 111 with loss 0.5014471411705017\n",
      "Epoch number: 121 with loss 0.4932042360305786\n",
      "Epoch number: 131 with loss 0.487758994102478\n",
      "Epoch number: 141 with loss 0.4776674509048462\n",
      "Epoch number: 151 with loss 0.4696337878704071\n",
      "Epoch number: 161 with loss 0.46046802401542664\n",
      "Epoch number: 171 with loss 0.4541384279727936\n",
      "Epoch number: 181 with loss 0.4480547308921814\n",
      "Epoch number: 191 with loss 0.44212403893470764\n",
      "Epoch number: 201 with loss 0.43598318099975586\n",
      "Epoch number: 211 with loss 0.4298897385597229\n",
      "Epoch number: 221 with loss 0.42314404249191284\n",
      "Epoch number: 231 with loss 0.41657447814941406\n",
      "Epoch number: 241 with loss 0.4205673336982727\n",
      "Epoch number: 251 with loss 0.40912064909935\n",
      "Epoch number: 261 with loss 0.40411487221717834\n",
      "Epoch number: 271 with loss 0.39977338910102844\n",
      "Epoch number: 281 with loss 0.3968846797943115\n",
      "Epoch number: 291 with loss 0.39247411489486694\n",
      "Epoch number: 301 with loss 0.3982275426387787\n",
      "Epoch number: 311 with loss 0.39253154397010803\n",
      "Epoch number: 321 with loss 0.3849288821220398\n",
      "Epoch number: 331 with loss 0.38000479340553284\n",
      "Epoch number: 341 with loss 0.4108700454235077\n",
      "Epoch number: 351 with loss 0.3905234634876251\n",
      "Epoch number: 361 with loss 0.3750622868537903\n",
      "Epoch number: 371 with loss 0.3676808476448059\n",
      "Epoch number: 381 with loss 0.3631243109703064\n",
      "Epoch number: 391 with loss 0.3616122603416443\n",
      "Epoch number: 401 with loss 0.363840788602829\n",
      "Epoch number: 411 with loss 0.3659994602203369\n",
      "Epoch number: 421 with loss 0.36732539534568787\n",
      "Epoch number: 431 with loss 0.35091033577919006\n",
      "Epoch number: 441 with loss 0.3737536072731018\n",
      "Epoch number: 451 with loss 0.3469487130641937\n",
      "Epoch number: 461 with loss 0.35338693857192993\n",
      "Epoch number: 471 with loss 0.3488769233226776\n",
      "Epoch number: 481 with loss 0.34174126386642456\n",
      "Epoch number: 491 with loss 0.33642736077308655\n",
      "tensor(0.1527)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "y = (y == '>50K').astype(int)\n",
    "import pandas as pd\n",
    "import torch \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "diabetes_df = pd.read_csv(\"diabetes.csv\")\n",
    "X = diabetes_df.drop('Outcome', axis=1).values\n",
    "y = diabetes_df['Outcome'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "print(X_train)\n",
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self,input_features=8,\n",
    "                 hidden1=20,hidden2=20,\n",
    "                 out_features=2):\n",
    "        super().__init__() \n",
    "        \"\"\"\n",
    "        super is a computed indirect reference\n",
    "        which means that it isolates changes and\n",
    "        makes sure the children in the layers of\n",
    "        multiple inheritance are calling \n",
    "        the right parents\n",
    "        \"\"\"\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "ann = ANN_Model()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(ann.parameters(), lr=0.01, weight_decay=0)\n",
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = ann.forward(X_train)\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "    final_loss.append(loss)\n",
    "\n",
    "    if epoch % 10 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss {loss}')\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "y_pred_class = y_pred.argmax(dim=1)  # Convert logits to predicted class\n",
    "mse = torch.mean((y_pred_class.float() - y_train.float())**2)\n",
    "print(mse)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (2), usually from a call to set_ticks, does not match the number of labels (233).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m         y_pred\u001b[38;5;241m.\u001b[39mappend(prediction\u001b[38;5;241m.\u001b[39margmax())\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay\n\u001b[1;32m----> 7\u001b[0m \u001b[43mConfusionMatrixDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\19133\\CSCI\\du_install\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:473\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.from_predictions\u001b[1;34m(cls, y_true, y_pred, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[0;32m    463\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\n\u001b[0;32m    464\u001b[0m     y_true,\n\u001b[0;32m    465\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m     normalize\u001b[38;5;241m=\u001b[39mnormalize,\n\u001b[0;32m    469\u001b[0m )\n\u001b[0;32m    471\u001b[0m disp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(confusion_matrix\u001b[38;5;241m=\u001b[39mcm, display_labels\u001b[38;5;241m=\u001b[39mdisplay_labels)\n\u001b[1;32m--> 473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticks_rotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxticks_rotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolorbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolorbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mim_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mim_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\19133\\CSCI\\du_install\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:181\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[1;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m colorbar:\n\u001b[0;32m    180\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_, ax\u001b[38;5;241m=\u001b[39max)\n\u001b[1;32m--> 181\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicted label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim((n_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m    191\u001b[0m plt\u001b[38;5;241m.\u001b[39msetp(ax\u001b[38;5;241m.\u001b[39mget_xticklabels(), rotation\u001b[38;5;241m=\u001b[39mxticks_rotation)\n",
      "File \u001b[1;32mc:\\Users\\19133\\CSCI\\du_install\\lib\\site-packages\\matplotlib\\artist.py:147\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_autogenerated_signature\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Artist\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\19133\\CSCI\\du_install\\lib\\site-packages\\matplotlib\\artist.py:1224\u001b[0m, in \u001b[0;36mArtist.set\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1221\u001b[0m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[0;32m   1223\u001b[0m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[1;32m-> 1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\19133\\CSCI\\du_install\\lib\\site-packages\\matplotlib\\artist.py:1216\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[38;5;124;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\19133\\CSCI\\du_install\\lib\\site-packages\\matplotlib\\artist.py:1192\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[1;34m(self, props, errfmt)\u001b[0m\n\u001b[0;32m   1189\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m   1190\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1191\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk))\n\u001b[1;32m-> 1192\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpchanged()\n",
      "File \u001b[1;32mc:\\Users\\19133\\CSCI\\du_install\\lib\\site-packages\\matplotlib\\axes\\_base.py:74\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_method(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\19133\\CSCI\\du_install\\lib\\site-packages\\matplotlib\\axis.py:2071\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[1;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[0;32m   2068\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2071\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2073\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2075\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2076\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[0;32m   2077\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (2), usually from a call to set_ticks, does not match the number of labels (233)."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAGdCAYAAAAotLvzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkqUlEQVR4nO3de3RU9bn/8c8MIRcCkxiUXCRgsFTAYlCQFPC3DkgsBqVQ8YInrSlywCrYYvorSA+gIhhFtJSLUK0V/RXr5ZxK1VPpoaHK8RjDTfwpchAkQiBOAgQYEshtZp8/gMEpwZLsycx3Mu/XWnstZ+/9nXlGY548z/e793ZYlmUJAAAYwxnuAAAAQCCSMwAAhiE5AwBgGJIzAACGITkDAGAYkjMAAIYhOQMAYBiSMwAAhokJ9Qf6fD5VVFSoS5cucjgcof54AIANlmXp+PHjysjIkNPZdvVdXV2dGhoabL9PbGys4uPjgxBRaIU8OVdUVCgzMzPUHwsACKLy8nJ17969Td67rq5OWT07y13ltf1eaWlpKisri7gEHfLk3KVLF0nS3q2XydWZrjrapx98u3+4QwDaRJMa9b7+7P9d3hYaGhrkrvKqbEtPubq0Pk94jvuUNXCvGhoaSM7/yJlWtquz09a/dMBkMY6O4Q4BaBunn8YQimlJV5fozRMhT84AAFwIr+WT18ajmbyWL3jBhBjJGQBgJJ8s+dT67GxnbLiRnAEARvLJJzu1r73R4RWdzXwAAAxG5QwAMJLXsuS1Wt+atjM23EjOAAAjRfOcM21tAAAMQ+UMADCST5a8UVo5k5wBAEairQ0AAIxB5QwAMFI0r9amcgYAGMkXhK2lNmzYoDFjxigjI0MOh0Nr1qzxH2tsbNTMmTPVv39/JSYmKiMjQ3fddZcqKioC3qO6ulr5+flyuVxKTk7WpEmTVFNT06I4SM4AAJxWW1ur7OxsLV++/JxjJ06c0NatWzVnzhxt3bpVf/zjH7Vz5059//vfDzgvPz9f27dv17p16/T2229rw4YNmjJlSovioK0NADCS1+Zq7daMzcvLU15eXrPHkpKStG7duoB9y5Yt0+DBg7Vv3z716NFDO3bs0Nq1a7Vp0yYNGjRIkrR06VKNHj1aixYtUkZGxgXFQeUMADCS17K/SZLH4wnY6uvrgxbjsWPH5HA4lJycLEkqKSlRcnKyPzFLUm5urpxOp0pLSy/4fUnOAAAjBWvOOTMzU0lJSf6tqKgoKPHV1dVp5syZuvPOO+VyuSRJbrdb3bp1CzgvJiZGKSkpcrvdF/zetLUBAO1aeXm5P3lKUlxcnO33bGxs1O233y7LsrRixQrb7/f3SM4AACP55JBXDlvjJcnlcgUkZ7vOJOa9e/dq/fr1Ae+dlpamqqqqgPObmppUXV2ttLS0C/4M2toAACP5LPtbsJ1JzLt27dJf//pXde3aNeD4kCFDdPToUW3ZssW/b/369fL5fMrJybngz6FyBgDgtJqaGu3evdv/uqysTNu2bVNKSorS09N16623auvWrXr77bfl9Xr988gpKSmKjY1V3759deONN2ry5MlauXKlGhsbNW3aNE2YMOGCV2pLJGcAgKG8NtvarRm7efNmjRgxwv+6sLBQklRQUKCHH35Yb775piRpwIABAeP+9re/afjw4ZKk1atXa9q0aRo5cqScTqfGjx+vJUuWtCgOkjMAwEjhSM7Dhw+X9Q23/fymY2ekpKTo5ZdfbvFnfx1zzgAAGIbKGQBgJJ/lkM+ysVrbxthwIzkDAIwUjra2KWhrAwBgGCpnAICRvHLKa6OG9AYxllAjOQMAjGTZnHO2mHMGACC4mHMGAADGoHIGABjJaznltWzMObfBvbVDheQMADCSTw75bDR4fYrc7ExbGwAAw1A5AwCMFM0LwkjOAAAj2Z9zpq0NAACChMoZAGCkUwvCbDz4grY2AADB5bN5+05WawMAgKChcgYAGCmaF4SRnAEARvLJGbU3ISE5AwCM5LUc8tp4spSdseHGnDMAAIahcgYAGMlrc7W2l7Y2AADB5bOc8tlYEOaL4AVhtLUBADAMlTMAwEi0tQEAMIxP9lZc+4IXSsjR1gYAwDBUzgAAI9m/CUnk1p8kZwCAkezfvjNyk3PkRg4AQDtF5QwAMBLPcwYAwDDR3NYmOQMAjGT/OufITc6RGzkAAO0UlTMAwEg+yyGfnZuQRPAjI0nOAAAj+Wy2tSP5OufIjRwAgHaKyhkAYCT7j4yM3PqT5AwAMJJXDnltXKtsZ2y4Re6fFQAAtFNUzgAAI9HWBgDAMF7Za017gxdKyEXunxUAALRTVM4AACPR1gYAwDA8+AIAAMNYNh8ZaXEpFQAACBYqZwCAkWhrAwBgmGh+KlXk/lkBAEA7ReUMADCS1+YjI+2MDTeSMwDASLS1AQCAMaicAQBG8skpn40a0s7YcCM5AwCM5LUc8tpoTdsZG26R+2cFAADtFJUzAMBI0bwgjOQMADCSZfOpVBZ3CAMAILi8cshr4+EVdsaGW+T+WQEAQDtF5QwAMJLPsjdv7LOCGEyIkZwj0CcfJur1Z7pp1yedVF3ZUQ89X6ahecckSU2N0qon0rVpvUtf7Y1Vosunq//PcU36ZYW6pjX53+Ouwf1UuT824H3vnlWhO+6vCul3AS7EHdMqNWz0MWV+q14NdU59trmTnl+Qrv1fxAec13dgrX48060+15yQ1yvt2Z6gX/5zLzXU0SSMRD6bc852xoYbyTkC1Z1wqteVJzXqzmrNm5QVcKz+pFO7P+mkf55eqV79TqrmWAetmHupHvpxLy1b+3nAuXf94ivl5R/2v+7U2ReS+IGWumpIrd5adbE+39ZJHWIs/fjBr/TYH/Zo8j9dofqTHSSdSswLVu/RK8u66ZnZl8rrlXr1q5PFjzUiUKuS8/Lly/Xkk0/K7XYrOztbS5cu1eDBg4MdG87j2uuP69rrjzd7LNHl0+OvfhGwb+qC/frp6CtUtb+junVv9O9P6OxTSremv38LwDj/mt8r4PVT03votU+3q/dVJ/VpaWdJ0j0PV2jN8xfrtWWp/vP+vrJGZPHJIZ+NRV12xoZbi2v+V199VYWFhXrooYe0detWZWdna9SoUaqqoh1qqlpPBzkclhKTvAH7X1vWTbde+R3dd8O39fozl8hLnkaESHSd+lk+fvRU1ZzUtVF9B57Q0cMx+tWbu/TKx9v15L/v1pWDa8IZJmw6c4cwO1tLbdiwQWPGjFFGRoYcDofWrFkTcNyyLM2dO1fp6elKSEhQbm6udu3aFXBOdXW18vPz5XK5lJycrEmTJqmmpmU/iy1Ozk8//bQmT56siRMnql+/flq5cqU6deqk3/3udy19K4RAQ51Dzy/I0PBxR5TY5Wx/b+ykg5q1Yq8Wvr5bo390WK8sTdVv52eEMVLgwjgcln7yyAF9urGT9u5MkCSl92yQJP2osFLvrO6qf83P0u5PEvT4q3uUkVUfznARYWpra5Wdna3ly5c3e3zhwoVasmSJVq5cqdLSUiUmJmrUqFGqq6vzn5Ofn6/t27dr3bp1evvtt7VhwwZNmTKlRXG0qK3d0NCgLVu2aNasWf59TqdTubm5KikpaXZMfX296uvP/s/h8XhaFCBar6lRWnDPZZIl3f/4/oBj4+856P/nXv3q1LGjpV/PzNTEWV8pNi6Clzii3Zv22AH17FOnn4/7ln+f83SZ8effd9V/vpoiSfri004acF2NRk2o1gtF6eEIFTaFY0FYXl6e8vLymj1mWZYWL16s2bNna+zYsZKkl156SampqVqzZo0mTJigHTt2aO3atdq0aZMGDRokSVq6dKlGjx6tRYsWKSPjwoqgFkV+6NAheb1epaamBuxPTU2V2+1udkxRUZGSkpL8W2ZmZks+Eq10JjFXHohV0StfBFTNzbnimhPyNjlUWR77jecB4TR1wX7l3ODRjFsv16Gvzv6sHq48VWfs/Txwjrl8d5y6XdoQ0hgRPD45/LfwbNV2es7Z4/EEbF8vGFuirKxMbrdbubm5/n1JSUnKycnxF6glJSVKTk72J2ZJys3NldPpVGlp6QV/VpuvM581a5aOHTvm38rLy9v6I6PemcR8oCxOj7+6W64U7z8cs2d7gpxOS8kXM/EME1maumC/ht54TDNuu1yV5XEBRyvLY3Xoqxh1v7wuYP+lvepVtZ8/OKNdZmZmQJFYVFTUqvc5U4R+U4HqdrvVrVu3gOMxMTFKSUk5bxHbnBa1tS+++GJ16NBBlZWVAfsrKyuVlpbW7Ji4uDjFxcU1ewytc7LWqYqys/9O3eWx+uLTBHVJblJKaqMenXxqvm3eS3vk8zpUXXXqP3OXZK86xlr6bHMn/c9HicoeelydOvu0Y0uiVj6UoevHH1GX5H+cyIFQm/bYAY34wRE9PDFLJ2ucuuiSU1cd1B7vcPoaZof+bUU3/ej/urXnswTt2Z6g3NuqlXl5veZPTglv8Gg1y+Zqbev02PLycrlcLv/+SMhJLUrOsbGxGjhwoIqLizVu3DhJks/nU3FxsaZNm9YW8aEZn3/cSTNuPTvf9puHL5Uk3XB7tX74c7c+/M8kSdJ9N/QJGLfw33Yre2iNOsZaeu9Pyfr9U2lqbHAoLbNBt0w5qFumHBRgojE/PnU9/qI/Bl4muGh6pta9dir5vvHbS9Qx3qefPFKhLsle7fksXrPu7KWv9pr/ixjNC9ZTqVwuV0Bybq0zRWhlZaXS08+uY6isrNSAAQP85/z91UtNTU2qrq4+bxHbnBZf51xYWKiCggINGjRIgwcP1uLFi1VbW6uJEye29K3QStlDa/SXim3nPf5NxySp91Un9eu3d33jOYBJRmVkX9B5ry1LDbjOGZHNtDuEZWVlKS0tTcXFxf5k7PF4VFpaqnvvvVeSNGTIEB09elRbtmzRwIEDJUnr16+Xz+dTTk7OBX9Wi5PzHXfcoYMHD2ru3Llyu90aMGCA1q5de04PHgCASFNTU6Pdu3f7X5eVlWnbtm1KSUlRjx49NH36dM2fP1+9e/dWVlaW5syZo4yMDH83uW/fvrrxxhs1efJkrVy5Uo2NjZo2bZomTJhwwSu1pVbeIWzatGm0sQEAbSpYbe2W2Lx5s0aMGOF/XVhYKEkqKCjQqlWrNGPGDNXW1mrKlCk6evSorrvuOq1du1bx8WevFFi9erWmTZumkSNHyul0avz48VqyZEmL4uDe2gAAI4Xj9p3Dhw+XZZ3/Xg8Oh0Pz5s3TvHnzzntOSkqKXn755RZ/9tdF7iM7AABop6icAQBGCkdb2xQkZwCAkaI5OdPWBgDAMFTOAAAjRXPlTHIGABgpmpMzbW0AAAxD5QwAMJKl1l2r/PXxkYrkDAAwUjS3tUnOAAAjRXNyZs4ZAADDUDkDAIwUzZUzyRkAYKRoTs60tQEAMAyVMwDASJblkGWj+rUzNtxIzgAAI4Xjec6moK0NAIBhqJwBAEaK5gVhJGcAgJGiec6ZtjYAAIahcgYAGIm2NgAAhonmtjbJGQBgJMtm5RzJyZk5ZwAADEPlDAAwkiXJsuyNj1QkZwCAkXxyyMEdwgAAgAmonAEARmK1NgAAhvFZDjmi9Dpn2toAABiGyhkAYCTLsrlaO4KXa5OcAQBGiuY5Z9raAAAYhsoZAGCkaK6cSc4AACNF82ptkjMAwEjRvCCMOWcAAAxD5QwAMNKpytnOnHMQgwkxkjMAwEjRvCCMtjYAAIahcgYAGMmSvWcyR3BXm+QMADATbW0AAGAMKmcAgJmiuK9NcgYAmMlmW1sR3NYmOQMAjMQdwgAAgDGonAEARorm1dokZwCAmSyHvXnjCE7OtLUBADAMlTMAwEjRvCCM5AwAMFMUX+dMWxsAAMNQOQMAjMRqbQAATBTBrWk7aGsDAGAYKmcAgJFoawMAYJooXq1NcgYAGMpxerMzPjIx5wwAgGGonAEAZqKtDQCAYaI4OdPWBgDAMCRnAICZzjwy0s7WAl6vV3PmzFFWVpYSEhJ0+eWX69FHH5X1tSdoWJaluXPnKj09XQkJCcrNzdWuXbuC/c1JzgAAM515KpWdrSWeeOIJrVixQsuWLdOOHTv0xBNPaOHChVq6dKn/nIULF2rJkiVauXKlSktLlZiYqFGjRqmuri6o3505ZwAAJH3wwQcaO3asbrrpJknSZZddpj/84Q/auHGjpFNV8+LFizV79myNHTtWkvTSSy8pNTVVa9as0YQJE4IWC5UzAMBMVhC2Fhg6dKiKi4v1+eefS5I+/vhjvf/++8rLy5MklZWVye12Kzc31z8mKSlJOTk5KikpafXXbA6VMwDATK2YNz5nvCSPxxOwOy4uTnFxceec/uCDD8rj8ahPnz7q0KGDvF6vFixYoPz8fEmS2+2WJKWmpgaMS01N9R8LFipnAEC7lpmZqaSkJP9WVFTU7HmvvfaaVq9erZdffllbt27Viy++qEWLFunFF18MccRUzgAAQzmsU5ud8ZJUXl4ul8vl399c1SxJv/jFL/Tggw/654779++vvXv3qqioSAUFBUpLS5MkVVZWKj093T+usrJSAwYMaH2gzaByBgCYKUhzzi6XK2A7X3I+ceKEnM7AtNihQwf5fD5JUlZWltLS0lRcXOw/7vF4VFpaqiFDhgTnO59G5QwAMFOQ5pwv1JgxY7RgwQL16NFDV155pT766CM9/fTTuvvuuyVJDodD06dP1/z589W7d29lZWVpzpw5ysjI0Lhx41ofZzNIzgAASFq6dKnmzJmj++67T1VVVcrIyNA999yjuXPn+s+ZMWOGamtrNWXKFB09elTXXXed1q5dq/j4+KDG4rCsll6mbY/H41FSUpKOfN5Lri501dE+jcoYEO4QgDbRZDXqXf1Jx44dC5jHDaYzeSLz6UflTGh90vOdrFN54Zw2jbWtUDkDAMzEgy8AAIApqJwBAGaK4sqZ5AwAMFOIV2ubhLY2AACGoXIGABgpWHcIi0QkZwCAmaJ4zpm2NgAAhiE5AwBgGNraAAAjOWRzzjlokYRe2JLzbTfkKcbZ/JNBgEjnHX5xuEMA2oS3qU76rz+F5sO4lAoAAJiCtjYAwExRvFqb5AwAMFMUJ2fa2gAAGIbKGQBgJO4QBgCAaWhrAwAAU1A5AwDMFMWVM8kZAGCkaJ5zpq0NAIBhqJwBAGaK4tt3kpwBAGZizhkAALMw5wwAAIxB5QwAMBNtbQAADGOzrR3JyZm2NgAAhqFyBgCYibY2AACGieLkTFsbAADDUDkDAIzEdc4AAMAYJGcAAAxDWxsAYKYoXhBGcgYAGCma55xJzgAAc0VwgrWDOWcAAAxD5QwAMBNzzgAAmCWa55xpawMAYBgqZwCAmWhrAwBgFtraAADAGFTOAAAz0dYGAMAwUZycaWsDAGAYKmcAgJGieUEYyRkAYKYobmuTnAEAZori5MycMwAAhqFyBgAYiTlnAABMQ1sbAACYgsoZAGAk2toAAJiGtjYAADAFlTMAwExRXDmTnAEARnKc3uyMj1S0tQEAMAyVMwDATLS1AQAwC5dSAQBgmiiunJlzBgDAMCRnAIC5LBtbKxw4cEA//OEP1bVrVyUkJKh///7avHnz2XAsS3PnzlV6eroSEhKUm5urXbt2tfrrnQ/JGQBgpDNzzna2ljhy5IiGDRumjh076p133tFnn32mp556ShdddJH/nIULF2rJkiVauXKlSktLlZiYqFGjRqmuri6o3505ZwAAJD3xxBPKzMzUCy+84N+XlZXl/2fLsrR48WLNnj1bY8eOlSS99NJLSk1N1Zo1azRhwoSgxULlDAAwk52W9tda2x6PJ2Crr69v9uPefPNNDRo0SLfddpu6deumq6++Ws8995z/eFlZmdxut3Jzc/37kpKSlJOTo5KSkqB+dZIzAMBIwWprZ2ZmKikpyb8VFRU1+3l79uzRihUr1Lt3b/3lL3/Rvffeq5/+9Kd68cUXJUlut1uSlJqaGjAuNTXVfyxYaGsDANq18vJyuVwu/+u4uLhmz/P5fBo0aJAee+wxSdLVV1+tTz/9VCtXrlRBQUFIYj2DyhkAYKYgtbVdLlfAdr7knJ6ern79+gXs69u3r/bt2ydJSktLkyRVVlYGnFNZWek/FiwkZwCAkUK9WnvYsGHauXNnwL7PP/9cPXv2lHRqcVhaWpqKi4v9xz0ej0pLSzVkyBDb3/fraGsDACDpgQce0NChQ/XYY4/p9ttv18aNG/Xss8/q2WeflSQ5HA5Nnz5d8+fPV+/evZWVlaU5c+YoIyND48aNC2osJGcAgJlCfPvOa6+9Vm+88YZmzZqlefPmKSsrS4sXL1Z+fr7/nBkzZqi2tlZTpkzR0aNHdd1112nt2rWKj4+3Eei5SM4AADOF4d7aN998s26++ebzHnc4HJo3b57mzZtnI7B/jOQMADBSND+VigVhAAAYhsoZAGCmKH5kJMkZAGAkh2XJYbU+w9oZG260tQEAMAyVMwDATLS1AQAwC6u1AQCAMaicAQBmoq0NAIBZaGsDAABjUDkDAMxEWxsAALNEc1ub5AwAMFMUV87MOQMAYBgqZwCAsSK5NW0HyRkAYCbLOrXZGR+haGsDAGAYKmcAgJFYrQ0AgGlYrQ0AAExB5QwAMJLDd2qzMz5SkZzbgdE/+FKjf/ClUtNPSpL2lnXRH37XW1s+TJUkFS37QFddczhgzJ/f6KnlT14V8liBYJgw5v/rX+7con9/p59W/L8cSdJTs99Rdj93wHlv/fUK/fp3Q8MRIoIhitvaJOd24FBVvFat6KuK8kTJIeWOLtecJzbppz/+J+0r6yJJWvunHvr9c1f4x9TVdQhXuIAtV/Q6qJtG7tQXey8659h/rP+2Vr1+tf91fQO/4hCZWjznvGHDBo0ZM0YZGRlyOBxas2ZNG4SFltj432naXJKqiv2dVVHeWS/9pq/qTsaoz5VH/OfU1XXQkep4/3byRMcwRgy0Tnxco2ZN3aBf/XaYamrjzjleVx+jI8c6+bcTJ2PDECWC5cxqbTtbpGrxn5W1tbXKzs7W3XffrVtuuaUtYoINTqel666vUHy8Vzs+PVtZjPjeAY0YtV9HquO18f1UvfJCb9XXU1Ugsvx0YolKP+qurZ9mKH/cx+ccHznsC+Ve94Wqjybow62Z+v0bA6ieI1kU34SkxT+1eXl5ysvLa4tYYEPPXh499ez7io316eTJDpo/a5DKvzzV0n5v3aWqcifo8MF4ZX3Lo4n37VD3HjVa8Mtrwxw1cOGGD9mj3pcd1n1zxjR7fP0HvVR5qLMOH0lQVo8jmjxhs7qnH9Mji0eGOFIEC9c5t6H6+nrV19f7X3s8nrb+yKh0YF9n3V/wT0rs3KhhI75S4extmjl1qMq/7KK1f+rpP2/vHpeqD8eraGmJ0i6tlftAYhijBi7MJSk1mnpXqWY8NkqNjc3/2vqP9WfXVJSVp6j6SIIWzf6L0rt59FWVK1ShAkHR5sm5qKhIjzzySFt/TNRranLqq9OJdvfOZH2771GNvX2Pli3MPufcnduTJUkZ3UnOiAy9ex3WRUl1WvnYm/59HTpY6t/HrXHf26G8u+6SzwpcQvM/X1wiSbo07TjJOVKxWrvtzJo1S4WFhf7XHo9HmZmZbf2xUc/htNSxY/MX+fXqfap7UX0oPpQhAa320acZ+pcZ4wL2/eKe97WvIkmvvtX/nMQsSZf3rJYkHT6SEIoQ0QZoa7ehuLg4xcWdu6oSwVPwkx3a/GE3HXQnKKFTk4Z/74D6X31Ycx74rtIurdXwGw5oc0k3eY7FKutbHk3+2XZ98lGKvvyCagKR4WRdR325P/DSqbr6GHlq4vTl/ouU3s2j64ft0cZt3eU5HqdePY7o3h9t1Mc7UlVWnhKmqIHWYxljO5B8Ub1+PucjpXStV21tjL7c7dKcB76rbZsu0cXdTmrAtQc19o49io/36mBVgv77b+l6ZVXvcIcNBE1Tk1PXfKdC42/8TPFxTaqq7qT/2thTq9ecO62DCMJq7QtXU1Oj3bt3+1+XlZVp27ZtSklJUY8ePYIaHC7Mr4sGnPfYoaoEPTh1WOiCAULk5/PPXjVysLqzfv7o6DBGg7ZAW7sFNm/erBEjRvhfn5lPLigo0KpVq4IWGAAA0arFyXn48OGyIrhVAACIEKzWBgDALNHc1uZ5zgAAGIbKGQBgJp91arMzPkKRnAEAZmLOGQAAszhkc845aJGEHnPOAAAYhsoZAGAm7hAGAIBZuJQKAAAYg8oZAGAmVmsDAGAWh2XJYWPe2M7YcKOtDQCAYaicAQBm8p3e7IyPUCRnAICRaGsDAABjUDkDAMzEam0AAAzDHcIAADALdwgDAADGoHIGAJiJtjYAAGZx+E5tdsZHKtraAAAYhsoZAGAm2toAABgmiq9zpq0NAIBhqJwBAEaK5ntrk5wBAGaK4jln2toAABiGyhkAYCZL9p7JHLmFM5UzAMBMZ+ac7Wx2PP7443I4HJo+fbp/X11dnaZOnaquXbuqc+fOGj9+vCorK21+03ORnAEAZrJ0dt65VVvrP3rTpk36zW9+o6uuuipg/wMPPKC33npLr7/+ut577z1VVFTolltusfc9m0FyBgDga2pqapSfn6/nnntOF110kX//sWPH9Pzzz+vpp5/W9ddfr4EDB+qFF17QBx98oA8//DCoMZCcAQBmslU1n13p7fF4Arb6+vpv/NipU6fqpptuUm5ubsD+LVu2qLGxMWB/nz591KNHD5WUlAT1q5OcAQBm8gVhk5SZmamkpCT/VlRUdN6PfOWVV7R169Zmz3G73YqNjVVycnLA/tTUVLndbjvf9Bys1gYAtGvl5eVyuVz+13Fxcec972c/+5nWrVun+Pj4UIXXLCpnAICRgrVa2+VyBWznS85btmxRVVWVrrnmGsXExCgmJkbvvfeelixZopiYGKWmpqqhoUFHjx4NGFdZWam0tLSgfncqZwCAmUJ8h7CRI0fqk08+Cdg3ceJE9enTRzNnzlRmZqY6duyo4uJijR8/XpK0c+dO7du3T0OGDGl9nM0gOQMAIKlLly76zne+E7AvMTFRXbt29e+fNGmSCgsLlZKSIpfLpfvvv19DhgzRd7/73aDGQnIGAJjJwHtr/+pXv5LT6dT48eNVX1+vUaNG6Zlnngn655CcAQBmMiA5v/vuuwGv4+PjtXz5ci1fvtz2e38TFoQBAGAYKmcAgJl8khw2x0cokjMAwEh2H15h98EX4URyBgCYyYA553BhzhkAAMNQOQMAzOSzJIeN6tcXuZUzyRkAYCba2gAAwBRUzgAAQ9msnBW5lTPJGQBgJtraAADAFFTOAAAz+SzZak2zWhsAgCCzfKc2O+MjFG1tAAAMQ+UMADBTFC8IIzkDAMzEnDMAAIaJ4sqZOWcAAAxD5QwAMJMlm5Vz0CIJOZIzAMBMtLUBAIApqJwBAGby+STZuJGIL3JvQkJyBgCYibY2AAAwBZUzAMBMUVw5k5wBAGaK4juE0dYGAMAwVM4AACNZlk+Wjcc+2hkbbiRnAICZLMtea5o5ZwAAgsyyOeccwcmZOWcAAAxD5QwAMJPPJzlszBsz5wwAQJDR1gYAAKagcgYAGMny+WTZaGtzKRUAAMFGWxsAAJiCyhkAYCafJTmis3ImOQMAzGRZkuxcShW5yZm2NgAAhqFyBgAYyfJZsmy0ta0IrpxJzgAAM1k+2WtrcykVAABBFc2VM3POAAAYJuSV85m/ZJp8DaH+aCBkmprqwh0C0CaamuolhaYqbbLqbbWmm9QYxGhCK+TJ+fjx45Kkd8ufC/VHA6GzN9wBAG3r+PHjSkpKapP3jo2NVVpamt53/9n2e6WlpSk2NjYIUYWWwwpxU97n86miokJdunSRw+EI5UdHJY/Ho8zMTJWXl8vlcoU7HCDo+BkPLcuydPz4cWVkZMjpbLuZ0bq6OjU02O+wxsbGKj4+PggRhVbIK2en06nu3buH+mOjnsvl4hcX2jV+xkOnrSrmr4uPj4/IpBosLAgDAMAwJGcAAAxDcm7n4uLi9NBDDykuLi7coQBtgp9xtEchXxAGAAC+GZUzAACGITkDAGAYkjMAAIYhOQMAYBiSczu2fPlyXXbZZYqPj1dOTo42btwY7pCAoNmwYYPGjBmjjIwMORwOrVmzJtwhAUFDcm6nXn31VRUWFuqhhx7S1q1blZ2drVGjRqmqqircoQFBUVtbq+zsbC1fvjzcoQBBx6VU7VROTo6uvfZaLVu2TNKpe5pnZmbq/vvv14MPPhjm6IDgcjgceuONNzRu3LhwhwIEBZVzO9TQ0KAtW7YoNzfXv8/pdCo3N1clJSVhjAwAcCFIzu3QoUOH5PV6lZqaGrA/NTVVbrc7TFEBAC4UyRkAAMOQnNuhiy++WB06dFBlZWXA/srKSqWlpYUpKgDAhSI5t0OxsbEaOHCgiouL/ft8Pp+Ki4s1ZMiQMEYGALgQMeEOAG2jsLBQBQUFGjRokAYPHqzFixertrZWEydODHdoQFDU1NRo9+7d/tdlZWXatm2bUlJS1KNHjzBGBtjHpVTt2LJly/Tkk0/K7XZrwIABWrJkiXJycsIdFhAU7777rkaMGHHO/oKCAq1atSr0AQFBRHIGAMAwzDkDAGAYkjMAAIYhOQMAYBiSMwAAhiE5AwBgGJIzAACGITkDAGAYkjMAAIYhOQMAYBiSMwAAhiE5AwBgGJIzAACG+V/+HzmV1SbU+gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = []\n",
    "with torch.no_grad(): \n",
    "    for i, data in enumerate(X_test):\n",
    "        prediction = ann(data)\n",
    "        y_pred.append(prediction.argmax())\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5\n",
    "(5 pts) Compare the performance of the neural networks to another model you created. Which performed better? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensionality reduction model gave a performace value of 0.10 vs the py.torch performance is 0.1527. This difference in performance might be related to the overfitting effect, loss of information during dimensionality reduction, or differing hyperparameter tuning of the dimensionality reduction model and PyTorch model. Neural networks capture more complex patterns and are subject to overfitting if not properly regularized, while dimensionality reduction simplifies the feature space, which might be beneficial for generalization. Regarding ways to further enhance the PyTorch model's results, one could think about regularization, hyperparameter tuning, and proper preprocessing of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "du_install",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
